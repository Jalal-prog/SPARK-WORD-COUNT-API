// After starting the SPARK SHELL for SCALA ($ spark-shell)
// Below is the API for word count in SPARK CONTEXT through loading a data file from local path and saving into HDFS path.

scala>  //cutting off 'scala>' for the below codes for easy copy.
       val lines = sc.textFile(“HDFS-PATH”)
       val wordCounts = lines.flatMap {line => line.split(" ")}
       .map(word => (word, 1))
       .reduceByKey(_ + _)
       wordCounts.saveAsTextFile(“Another-HDFS-path”)   // untill this the code is executed
wordCounts.foreach(println) // if you want to see print the result in the screen. 
